{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 00:27:53,869\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import yaml\n",
    "from train_eval.trainer import Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'op' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36308/1121195827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtarget_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfolded_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msource_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msource_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_unfolded_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'op' is not defined"
     ]
    }
   ],
   "source": [
    "def get_unfolded_feature(feature,kernel,mask):\n",
    "    ## Input shape B,C,H,W\n",
    "    channel=feature.shape[1]\n",
    "    unfold = nn.Unfold(kernel_size=(kernel, kernel), dilation=1, padding=kernel//2, stride=(1, 1))\n",
    "    unfolded_feature=unfold(feature).permute(0,2,1) ## B,Number of slided window, channel*Number of elements in every window\n",
    "    # unfolded_feature=unfolded_feature.view(unfolded_feature.shape[0],unfolded_feature.shape[1],channel,kernel**2)\n",
    "    current_node_feat=feature.view(feature.shape[0],channel,-1).permute(0,2,1)## B,Number of slided window, channel\n",
    "    # unfolded_feature=(unfolded_feature*mask.unsqueeze(-1)).to_sparse()\n",
    "    # current_node_feat=(current_node_feat*mask.unsqueeze(-1)).to_sparse()\n",
    "    target_feat=[]\n",
    "    source_feat=[]\n",
    "    for idx,batch in enumerate(current_node_feat):\n",
    "        source_feat.append(batch[mask[idx]])\n",
    "        target_feat.append(unfolded_feature[idx][mask[idx]])\n",
    "    return source_feat,target_feat\n",
    "source_feat,target_feat=get_unfolded_feature(op,15,mask_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coord,y_coord=torch.meshgrid(torch.arange(15//2,-((15//2)+1),-1),\n",
    "                                torch.arange(-(15//2),((15//2)+1),1))\n",
    "diff=torch.cat([x_coord.unsqueeze(0),y_coord.unsqueeze(0)],dim=0)\n",
    "diff=diff.view(2,-1).T\n",
    "# diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/stanliu/code/pgp/PGP/configs/raster.yml\", 'r') as yaml_file:\n",
    "    cfg = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_type = cfg['dataset'] + '_' + cfg['agent_setting'] + '_' + cfg['input_representation']\n",
    "# cfg\n",
    "# cfg['encoder_args']\n",
    "# cfg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 38.524 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 10.3 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from train_eval.trainer import Trainer\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# import os\n",
    "# writer = SummaryWriter(log_dir=os.path.join('/home/stanliu/code/pgp/PGP/output/test_ram', 'tensorboard_logs'))\n",
    "trainer = Trainer(cfg, \"/home/stanliu/data/mnt/nuScenes/\", \"/home/stanliu/code/pgp/PGP/preprocess_raster\")\n",
    "# trainer = Trainer(cfg, \"/home/stanliu/data/mnt/nuScenes/\", \"/home/stanliu/code/pgp/PGP/preprocess_raster\",checkpoint_path='/home/stanliu/code/pgp/PGP/output/test_ram/checkpoints/8.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_eval.utils as u\n",
    "for i,data in enumerate(trainer.tr_dl):\n",
    "    torch.cuda.empty_cache()\n",
    "    # Load data\n",
    "    data = u.send_to_device(u.convert_double_to_float(data))\n",
    "    data_test=data['inputs']\n",
    "    gt_test=data['ground_truth']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: [                    ] 0 %, ETA: 83153s, Metrics: { focal_loss: nan, min_ade_loss: 5.71, miss_rate_10: 1.00, min_ade_loss: 5.71, miss_rate_5: 1.00, min_fde_10: 4.47 }"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_scalar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26928/3669868755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Log val metrics for the complete epoch to tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensorboard_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/pgp/PGP/train_eval/trainer.py\u001b[0m in \u001b[0;36mlog_tensorboard_val\u001b[0;34m(self, epoch_metrics)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'minibatch_count'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'time_elapsed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0mmetric_val\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mepoch_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'minibatch_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_scalar'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import train_eval.utils as u\n",
    "mode = 'val'\n",
    "with torch.no_grad():\n",
    "    if mode == 'val':\n",
    "        trainer.model.eval()\n",
    "\n",
    "    # Initialize epoch metrics\n",
    "    epoch_metrics = trainer.initialize_metrics_for_epoch(mode)\n",
    "\n",
    "    # Main loop\n",
    "    st_time = time.time()\n",
    "    for i, data in enumerate(trainer.tr_dl):\n",
    "        torch.cuda.empty_cache()\n",
    "        # Load data\n",
    "        data = u.send_to_device(u.convert_double_to_float(data))\n",
    "        data['inputs']['gt_traj']= None\n",
    "        # Forward pass\n",
    "        predictions = trainer.model(data['inputs'])\n",
    "\n",
    "\n",
    "        # Compute loss and backprop if training\n",
    "\n",
    "        # Keep time\n",
    "        minibatch_time = time.time() - st_time\n",
    "        st_time = time.time()\n",
    "\n",
    "        # Aggregate metrics\n",
    "        minibatch_metrics, epoch_metrics = trainer.aggregate_metrics(epoch_metrics, minibatch_time,\n",
    "                                                                    predictions, data['ground_truth'], mode)\n",
    "\n",
    "\n",
    "\n",
    "        # Display metrics at a predefined frequency\n",
    "        # if i % trainer.log_period == trainer.log_period - 1:\n",
    "        trainer.print_metrics(epoch_metrics, trainer.tr_dl, mode)\n",
    "        break\n",
    "\n",
    "    # Log val metrics for the complete epoch to tensorboard\n",
    "    if mode == 'val':\n",
    "        trainer.log_tensorboard_val(epoch_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal=trainer.losses[0]\n",
    "ade=trainer.losses[1]\n",
    "# dri_loss=trainer.losses[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['gt_traj']=data['ground_truth']['traj']\n",
    "data_test['gt_traj']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 488, 488])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['ground_truth']['traj']\n",
    "map_representation = data_test['map_representation'][0]\n",
    "mask=data_test['map_representation'][1]\n",
    "\n",
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "unfold = nn.Unfold(kernel_size=(7, 7), dilation=1, padding=7//2, stride=(1, 1))\n",
    "unfold(mask.unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.library.RasterSampler import *\n",
    "sampler = Sampler(cfg['aggregator_args'],resolution=1.0,apply_mask=True)\n",
    "nodes_2D=sampler.sample_goals(mask)\n",
    "mask_under=sampler.sample_mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(map_representation[0].permute(1,2,0))\n",
    "plt.show()\n",
    "plt.imshow(mask[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0019, 0.0201, 0.0439, 0.0201, 0.0019],\n",
       "          [0.0201, 0.2096, 0.4578, 0.2096, 0.0201],\n",
       "          [0.0439, 0.4578, 1.0000, 0.4578, 0.0439],\n",
       "          [0.0201, 0.2096, 0.4578, 0.2096, 0.0201],\n",
       "          [0.0019, 0.0201, 0.0439, 0.0201, 0.0019]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import exp\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss#/gauss.sum()\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 0.8).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "window=create_window(5, 1)\n",
    "window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data_test['surrounding_agent_representation'][4,:3].permute(1,2,0))\n",
    "plt.show()\n",
    "# plt.imshow(test_heatmap[0,0])\n",
    "# plt.show()\n",
    "# data['ground_truth']['traj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['map_representation'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lane_node_feats has shape of ',data_test['map_representation']['lane_node_feats'].shape)\n",
    "print('lane_node_masks has shape of ',data_test['map_representation']['lane_node_masks'].shape)\n",
    "print('s_next has shape of ',data_test['map_representation']['s_next'].shape)\n",
    "print('edge_type has shape of ',data_test['map_representation']['edge_type'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         3.58%      10.397ms         3.58%      10.397ms      58.410us           0 b           0 b     849.36 Mb     849.36 Mb           178  \n",
      "                    aten::resize_         0.20%     588.359us         0.20%     588.359us      11.315us           0 b           0 b     176.06 Mb     176.06 Mb            52  \n",
      "              aten::empty_strided         0.48%       1.397ms         0.48%       1.397ms     279.439us       1.82 Mb       1.82 Mb      88.00 Mb      88.00 Mb             5  \n",
      "                         aten::to         0.04%     126.285us         2.11%       6.132ms     681.328us       1.82 Mb           0 b      88.00 Mb           0 b             9  \n",
      "                      aten::copy_         1.61%       4.688ms         1.61%       4.688ms     585.956us           0 b           0 b           0 b           0 b             8  \n",
      "                        aten::cat         0.01%      43.125us         0.30%     860.626us     286.875us           0 b           0 b      88.03 Mb           0 b             3  \n",
      "                       aten::_cat         0.09%     260.440us         0.28%     817.501us     272.500us           0 b           0 b      88.03 Mb           0 b             3  \n",
      "                     aten::stride         0.02%      67.433us         0.02%      67.433us       0.453us           0 b           0 b           0 b           0 b           149  \n",
      "                     aten::narrow         0.00%      14.340us         0.01%      40.203us      20.102us           0 b           0 b           0 b           0 b             2  \n",
      "                      aten::slice         0.02%      60.907us         0.03%      80.551us       8.055us           0 b           0 b           0 b           0 b            10  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 290.427ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd.profiler import profile, record_function\n",
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    encodings=trainer.model.encoder(data_test)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::empty        61.46%      15.274ms        61.46%      15.274ms     227.969us           0 b           0 b       9.57 Gb       9.57 Gb            67  \n",
      "                   aten::resize_         3.08%     765.613us         3.08%     765.613us      42.534us     234.47 Kb     234.47 Kb     309.74 Mb     309.74 Mb            18  \n",
      "             aten::empty_strided         0.28%      68.526us         0.28%      68.526us      17.131us     116.28 Kb     116.28 Kb       1.25 Mb       1.25 Mb             4  \n",
      "                        aten::to         0.26%      63.558us         2.30%     572.548us      81.793us     116.28 Kb           0 b       1.25 Mb           0 b             7  \n",
      "                 aten::unsqueeze         0.67%     166.376us         0.75%     186.496us      46.624us           0 b           0 b           0 b           0 b             4  \n",
      "                aten::as_strided         0.60%     149.208us         0.60%     149.208us       2.446us           0 b           0 b           0 b           0 b            61  \n",
      "                    aten::repeat         0.52%     128.714us         2.28%     565.755us     282.878us           0 b           0 b       2.25 Mb           0 b             2  \n",
      "                    aten::expand         0.22%      55.223us         0.28%      70.821us      10.117us           0 b           0 b           0 b           0 b             7  \n",
      "                     aten::alias         0.06%      15.533us         0.06%      15.533us       7.767us           0 b           0 b           0 b           0 b             2  \n",
      "                    aten::unfold         0.48%     118.938us         0.68%     168.016us      24.002us           0 b           0 b           0 b           0 b             7  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 24.851ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    agg_feat=trainer.model.aggregator(encodings)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))\n",
    "\n",
    "# connectivities=agg_feat['node_connectivity']\n",
    "# mask_map=agg_feat['under_sampled_mask']\n",
    "# init=agg_feat['initial_states']\n",
    "# print(connectivities.requires_grad)\n",
    "# print(mask_map.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['node_connectivity', 'under_sampled_mask', 'feature', 'target_encodings'])\n",
      "torch.Size([16646, 625])\n"
     ]
    }
   ],
   "source": [
    "print(agg_feat.keys())\n",
    "print(agg_feat['node_connectivity'][0].shape)\n",
    "# inputs=agg_feat\n",
    "# attn_output_weights = inputs['node_connectivity']\n",
    "# print(attn_output_weights[0].shape)\n",
    "# init_states=inputs['initial_states']\n",
    "# target_encodings = inputs['target_encodings']\n",
    "# map_feature=inputs['feature'].permute(0,2,3,1) \n",
    "# mask=inputs['under_sampled_mask']  \n",
    "      \n",
    "# print(agg_feat['node_connectivity'].shape)\n",
    "# print((agg_feat['initial_states'].indices().nelement() * agg_feat['initial_states'].indices().element_size() + agg_feat['initial_states'].values().nelement() *agg_feat['initial_states'].values().element_size()) / 1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.decoders.ram_decoder import get_index\n",
    "self=trainer.model.aggregator\n",
    "init_states=torch.zeros(1,self.H,self.W)\n",
    "init_states[:,self.compensation.long()]=1\n",
    "init_states=init_states[:,self.source_row-self.center_row:][agg_feat['under_sampled_mask'].view(1,self.H,self.W)[:,self.source_row-self.center_row:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16646])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices=get_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feat=op.view(op.shape[0],op.shape[1],-1).permute(0,2,1)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  aten::empty         3.99%       7.977ms         3.99%       7.977ms       3.963us         640 b         640 b      45.74 Mb      45.74 Mb          2013  \n",
      "                aten::resize_         2.37%       4.731ms         2.37%       4.731ms       3.571us     235.09 Kb     235.09 Kb      13.21 Mb      13.21 Mb          1325  \n",
      "          aten::empty_strided         0.04%      88.297us         0.04%      88.297us       8.027us           0 b           0 b     268.00 Kb     268.00 Kb            11  \n",
      "                 aten::conv2d         0.03%      62.755us         0.62%       1.234ms     411.285us           0 b           0 b      21.80 Mb           0 b             3  \n",
      "            aten::convolution         0.02%      45.584us         0.59%       1.171ms     390.367us           0 b           0 b      21.80 Mb           0 b             3  \n",
      "           aten::_convolution         0.06%     112.926us         0.56%       1.126ms     375.172us           0 b           0 b      21.80 Mb           0 b             3  \n",
      "             aten::contiguous         0.90%       1.795ms         3.10%       6.196ms       7.631us           0 b           0 b      80.00 Kb           0 b           812  \n",
      "                 aten::stride         0.14%     287.968us         0.14%     287.968us       0.415us           0 b           0 b           0 b           0 b           694  \n",
      "             aten::leaky_relu         0.10%     200.884us         0.12%     231.834us     115.917us           0 b           0 b      16.35 Mb           0 b             2  \n",
      "                   aten::view         0.36%     717.005us         0.36%     717.005us       3.567us           0 b           0 b           0 b           0 b           201  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 199.852ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    predictions=trainer.model.decoder(agg_feat)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))\n",
    "# print(predictions['pred'].element_size() * predictions['pred'].nelement()/ 1024**2)\n",
    "# pred=predictions['pred'].to_sparse()\n",
    "# print(pred.element_size() * pred.nelement()/ 1024**2)\n",
    "\n",
    "# print((pred.indices().nelement() * pred.indices().element_size() + pred.values().nelement() * pred.values().element_size()) / 1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3582],\n",
      "         [0.1584],\n",
      "         [0.1020],\n",
      "         [0.0510],\n",
      "         [0.0437],\n",
      "         [0.0325],\n",
      "         [0.0227],\n",
      "         [0.0179],\n",
      "         [0.0186],\n",
      "         [0.0184],\n",
      "         [0.0178],\n",
      "         [0.0173]],\n",
      "\n",
      "        [[0.4303],\n",
      "         [0.2177],\n",
      "         [0.1216],\n",
      "         [0.0792],\n",
      "         [0.0687],\n",
      "         [0.0575],\n",
      "         [0.0365],\n",
      "         [0.0202],\n",
      "         [0.0148],\n",
      "         [0.0130],\n",
      "         [0.0120],\n",
      "         [0.0108]],\n",
      "\n",
      "        [[0.3556],\n",
      "         [0.1934],\n",
      "         [0.1086],\n",
      "         [0.0768],\n",
      "         [0.0568],\n",
      "         [0.0367],\n",
      "         [0.0304],\n",
      "         [0.0190],\n",
      "         [0.0181],\n",
      "         [0.0163],\n",
      "         [0.0147],\n",
      "         [0.0136]],\n",
      "\n",
      "        [[0.2583],\n",
      "         [0.1629],\n",
      "         [0.1187],\n",
      "         [0.0900],\n",
      "         [0.0696],\n",
      "         [0.0543],\n",
      "         [0.0454],\n",
      "         [0.0435],\n",
      "         [0.0425],\n",
      "         [0.0421],\n",
      "         [0.0419],\n",
      "         [0.0417]]], device='cuda:0', grad_fn=<MaxBackward0>)\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]], device='cuda:0', grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print(predictions['pred'].shape)\n",
    "normalized_pred=predictions['pred']/(torch.max(predictions['pred'],dim=-1,keepdim=True)[0])\n",
    "print(torch.max(predictions['pred'],dim=-1,keepdim=True)[0])\n",
    "print(torch.max(normalized_pred,dim=-1,keepdim=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal=trainer.losses[0]\n",
    "focal.horizon=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "traj_idx=0\n",
    "idx=2\n",
    "import matplotlib.pyplot as plt\n",
    "from models.decoders.ram_decoder import get_index,get_dense\n",
    "gt_map=trainer.losses[0].generate_gtmap(predictions['traj'][:,traj_idx].view(predictions['traj'].shape[0],-1,predictions['traj'].shape[-1]).clone().detach(),predictions['mask'],visualize=True)\n",
    "gt_map=torch.clamp(torch.sum(gt_map,dim=1,keepdim=True),0.0,1.0)\n",
    "mask_map=gt_map.clone()\n",
    "mask_map[predictions['mask'].view(gt_map.shape)]=0.005\n",
    "gt_map+=mask_map\n",
    "gt_map=gt_map.repeat(1,3,1,1)\n",
    "gt_map*=127\n",
    "endpoints=predictions['endpoints']\n",
    "for batch in range(gt_map.shape[0]):\n",
    "    for i,point in enumerate(endpoints[batch]):\n",
    "        if i== traj_idx:\n",
    "            x,y=point\n",
    "            gt_map[batch,-1,max(0,x-2):min(x+3,trainer.losses[0].H),max(0,y-2):min(trainer.losses[0].W,y+3)]=255\n",
    "            gt_map[batch,:-1,max(0,x-2):min(x+3,trainer.losses[0].H),max(0,y-2):min(trainer.losses[0].W,y+3)]=0\n",
    "        else:\n",
    "            x,y=point\n",
    "            gt_map[batch,0,max(0,x-1):min(x+1,trainer.losses[0].H),max(0,y-1):min(trainer.losses[0].W,y+1)]=255\n",
    "            gt_map[batch,1:,max(0,x-1):min(x+3,trainer.losses[0].H),max(0,y-1):min(trainer.losses[0].W,y+1)]=0\n",
    "\n",
    "gt_map=gt_map.permute(0,2,3,1)\n",
    "# normalize_factor,_=torch.max(dense_pred.view(dense_pred.shape[0],-1),dim=-1)\n",
    "plt.imshow(gt_map[idx].cpu())\n",
    "plt.show()\n",
    "# plt.imshow(mask[idx])\n",
    "# plt.show()\n",
    "# gt_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# idx=3\n",
    "# traj_idx=0\n",
    "import matplotlib.pyplot as plt\n",
    "from models.decoders.ram_decoder import get_index,get_dense\n",
    "gt_map=trainer.losses[0].generate_gtmap(data['ground_truth']['traj'],predictions['mask'],visualize=True)\n",
    "gt_map=torch.sum(gt_map,dim=1,keepdim=True)\n",
    "mask_map=torch.zeros_like(gt_map)\n",
    "mask_map[predictions['mask'].view(gt_map.shape)]=1\n",
    "gt_map+=mask_map\n",
    "# gt_map=gt_map.permute(0,2,3,1)\n",
    "# normalize_factor,_=torch.max(dense_pred.view(dense_pred.shape[0],-1),dim=-1)\n",
    "plt.imshow(gt_map[idx].squeeze(0).cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=ade.compute(predictions,gt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sum=predictions['init_states'].view(predictions['init_states'].shape[0],-1).sum(dim=-1)\n",
    "corrupt_idx=torch.argmin(sum).item()\n",
    "corrupt_map=predictions['mask'][corrupt_idx].view(trainer.model.decoder.H,trainer.model.decoder.W)\n",
    "print(corrupt_map[trainer.model.decoder.compensation[0]-1:trainer.model.decoder.compensation[0]+2,trainer.model.decoder.compensation[1]-1:trainer.model.decoder.compensation[1]+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pos=torch.zeros([122,122],device=predictions['mask'].device)\n",
    "init_pos[trainer.model.decoder.compensation[0],trainer.model.decoder.compensation[1]]=1\n",
    "mask_local=(predictions['mask'][0].view(122,122))[trainer.model.decoder.compensation[0]-1:trainer.model.decoder.compensation[0]+2,trainer.model.decoder.compensation[1]-1:trainer.model.decoder.compensation[1]+2]\n",
    "valid_node_num=mask_local.float().sum()\n",
    "init_pos[trainer.model.decoder.compensation[0]-1:trainer.model.decoder.compensation[0]+2,trainer.model.decoder.compensation[1]-1:trainer.model.decoder.compensation[1]+2]=1/valid_node_num.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1111, 0.1111, 0.1111],\n",
       "        [0.1111, 0.1111, 0.1111],\n",
       "        [0.1111, 0.1111, 0.1111]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_pos[trainer.model.decoder.compensation[0]-1:trainer.model.decoder.compensation[0]+2,trainer.model.decoder.compensation[1]-1:trainer.model.decoder.compensation[1]+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((init_pos.view(-1))[predictions['mask'][0]]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss+=ade.compute(predictions,gt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14016, 10258], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['mask'].sum(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = agg_feat\n",
    "attn_output_weights = inputs['node_connectivity']\n",
    "init_states=inputs['initial_states']\n",
    "\n",
    "\n",
    "mask=inputs['under_sampled_mask']\n",
    "target_encodings = inputs['target_encodings']\n",
    "map_feature=inputs['feature'].permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "predictions=torch.empty([init_states.shape[0],0,init_states.shape[-1]],device=attn_output_weights.device)\n",
    "prev_states=init_states.unsqueeze(1).to_dense()\n",
    "\n",
    "for step in range(12):\n",
    "    predictions=torch.cat((predictions,torch.bmm(prev_states,attn_output_weights)),dim=1)\n",
    "    prev_states=predictions[:,step].unsqueeze(1)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_extent= [-61, 61, -22, 100]\n",
    "from models.decoders.ram_decoder import get_dense,get_index\n",
    "nodes_2D=get_index(predictions[:,-1].unsqueeze(1),mask)\n",
    "dense_pred=get_dense(predictions[:,-1].unsqueeze(1),nodes_2D,122,122)\n",
    "endpoints,confidences = trainer.model.decoder.endpoint_sampler(dense_pred)\n",
    "endpoints=endpoints.long()\n",
    "concat_feature=torch.empty([0,12,90],device=attn_output_weights.device)\n",
    "x_coord,y_coord=torch.meshgrid(torch.arange(map_extent[-1],map_extent[-2],-1), ##### SHould be changed when image size changes\n",
    "                                torch.arange(map_extent[0],map_extent[1],1))\n",
    "indices=torch.cat([x_coord.unsqueeze(-1),y_coord.unsqueeze(-1)],dim=-1).to(attn_output_weights.device)\n",
    "for batch_idx in range(len(dense_pred)):\n",
    "    map_feat = (map_feature[batch_idx])[endpoints[batch_idx,:,0],endpoints[batch_idx,:,1]]\n",
    "    diff = indices[endpoints[batch_idx,:,0],endpoints[batch_idx,:,1]].float()\n",
    "\n",
    "    feature=torch.cat([map_feat,trainer.model.decoder.diff_encoder(diff),target_encodings[batch_idx].repeat(trainer.model.decoder.endpoint_sampler._n_targets,1)],dim=-1).unsqueeze(0)\n",
    "    concat_feature=torch.cat([concat_feature,feature],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=predictions['pred']\n",
    "mask=predictions['mask']\n",
    "traj_gt = gt_test['traj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    swapped=torch.zeros_like(traj_gt).to(pred.device)\n",
    "    swapped[:,:,0],swapped[:,:,1]=-traj_gt[:,:,1],traj_gt[:,:,0]\n",
    "    coord=torch.round(swapped/trainer.losses[0].resolution+trainer.losses[0].compensation).int()\n",
    "    coord=torch.clamp(coord,0,122)\n",
    "    gt_map=torch.zeros([6,12,122,122],device=pred.device)\n",
    "    for batch in range(6):\n",
    "        for t in range(12):\n",
    "            x,y=coord[batch,t]\n",
    "            gt_map[batch,t,x,y]=1##Only one ground truth in each heatmap layer\n",
    "    gs_map=F.conv2d(gt_map, trainer.losses[0].window, padding = trainer.losses[0].window_size//2, groups = trainer.losses[0].horizon)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    loss_mask = (reduced_gts == 1).float()\n",
    "    pred_heatmap = torch.clamp(pred, min=1e-4)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    loss=-torch.sum(\n",
    "                    torch.pow(pred_heatmap - reduced_maps, 2) * (\n",
    "                    loss_mask * torch.log(pred_heatmap)\n",
    "                    +\n",
    "                    (1-loss_mask) * (torch.pow(1 - reduced_maps, 4) * torch.log(1 - pred_heatmap))\n",
    "                )\n",
    "            )\n",
    "    loss.backward()\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    trainer.optimizer.step()\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "    gs_map=gs_map.view([6,12,-1])\n",
    "    gt_map=gt_map.view([6,12,-1])\n",
    "    max_num=max(mask.sum(dim=1))\n",
    "    reduced_maps=[]\n",
    "    reduced_gts=[]\n",
    "    for i,batch in enumerate(gs_map):\n",
    "        reduced_map=batch[mask[i].repeat(12,1)].view(12,-1)\n",
    "        reduced_gt=gt_map[i][mask[i].repeat(12,1)].view(12,-1)\n",
    "        aug_map=torch.cat((reduced_map, torch.zeros(12,max_num - reduced_map.size(1),device=pred.device)), -1)\n",
    "        aug_gt=torch.cat((reduced_gt, torch.zeros(12,max_num - reduced_map.size(1),device=pred.device)), -1)\n",
    "        reduced_maps.append(aug_map.unsqueeze(0))\n",
    "        reduced_gts.append(aug_gt.unsqueeze(0))\n",
    "    reduced_maps=torch.cat(reduced_maps,dim=0).to(pred.device)\n",
    "    reduced_gts=torch.cat(reduced_gts,dim=0).to(pred.device)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_gts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(pred,mask):\n",
    "    x_coord,y_coord=torch.meshgrid(torch.arange(0,122,1),\n",
    "                                torch.arange(0,122,1))\n",
    "    nodes_candidates=torch.cat((x_coord.unsqueeze(0),y_coord.unsqueeze(0)),dim=0).view(2,-1).T\n",
    "    nodes_2D=torch.zeros([mask.shape[0],pred.shape[-1],2])\n",
    "    for i in range(mask.shape[0]):\n",
    "        nodes_batch=nodes_candidates[mask[i]]\n",
    "        nodes_2D[i,:nodes_batch.shape[0]]=nodes_batch\n",
    "    return nodes_2D.int().permute(0,2,1).to(pred.device)\n",
    "nodes_2D=get_index(pred,mask)\n",
    "nodes_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense(pred,nodes_2D,H,W):\n",
    "    dense_rep=torch.empty(0,pred.shape[1],H,W,device=pred.device)\n",
    "    for batch in range(pred.shape[0]):\n",
    "        batch_heatmap=torch.empty(0,H,W,device=pred.device)\n",
    "        for step in range(pred.shape[1]):\n",
    "            heatmap=torch.sparse_coo_tensor(nodes_2D[batch],pred[batch,step],(122,122))\n",
    "            batch_heatmap=torch.cat((batch_heatmap,heatmap.to_dense().unsqueeze(0)),dim=0)\n",
    "        dense_rep=torch.cat((dense_rep,batch_heatmap.unsqueeze(0)),dim=0)\n",
    "    return dense_rep\n",
    "dense_rep=get_dense(pred,nodes_2D,122,122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['probs']=predictions['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with profile( profile_memory=True, record_shapes=True) as prof:\n",
    "\n",
    "# loss=pred.sum()\n",
    "    loss=focal.compute(predictions,gt_test)\n",
    "    loss+=ade.compute(predictions,gt_test)\n",
    "    loss.backward()\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions['pred']\n",
    "mask_da = predictions['mask'].view(-1,pred.shape[-2],pred.shape[-1]).unsqueeze(1)\n",
    "ground_truth = gt_test\n",
    "traj_gt = ground_truth['traj'] if type(ground_truth) == dict else ground_truth\n",
    "true_heatmap,gs_map = focal.generate_gtmap(traj_gt,pred.shape)\n",
    "gs_map=gs_map*mask_da\n",
    "mask = (true_heatmap == 1).float()\n",
    "pred_heatmap = torch.clamp(pred, min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= focal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions['pred']\n",
    "mask = predictions['mask'].view(-1,pred.shape[-2],pred.shape[-1]).unsqueeze(1)\n",
    "non_drivable_area_mask=~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(non_drivable_area_mask[0,0].cpu())\n",
    "plt.show()\n",
    "plt.imshow(torch.zeros_like(non_drivable_area_mask[0,0].cpu()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "map_extent=[ -50, 50, -20, 80 ]\n",
    "img_size=[400,400]\n",
    "resolution = (map_extent[1] - map_extent[0]) /  img_size[1]\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=\"/home/stanliu/data/mnt/nuScenes/\", verbose=True)\n",
    "helper=PredictHelper(nusc)\n",
    "map_rasterizer = StaticLayerRasterizer(helper,\n",
    "                                        resolution=resolution,\n",
    "                                        meters_ahead=map_extent[3],\n",
    "                                        meters_behind=-map_extent[2],\n",
    "                                        meters_left=-map_extent[0],\n",
    "                                        meters_right=map_extent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "target_agent_representation = data_test['target_agent_representation']\n",
    "surrounding_agent_representation = data_test['surrounding_agent_representation']\n",
    "map_representation = data_test['map_representation'][0]\n",
    "mask= data_test['map_representation'][1].type(torch.bool)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(np.array(mask[idx]))\n",
    "plt.show()\n",
    "plt.imshow(np.array(map_representation[idx]).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.models import resnet34\n",
    "# input = torch.cat((map_representation, surrounding_agent_representation), dim=1)\n",
    "# resnet_model = resnet34(pretrained=False)\n",
    "# conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# modules = list(resnet_model.children())[:-2]\n",
    "\n",
    "# modules[0] = conv1_new\n",
    "# backbone = nn.Sequential(*modules)\n",
    "# data_test['target_agent_representation'].float().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.encoders.raster_encoder import *\n",
    "encoder=RasterEncoder(cfg['encoder_args'])\n",
    "# encodings=encoder.forward(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings['context_encoding'][\"combined\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.modules as nn\n",
    "fake_map_encodings=torch.randn(32, 512, 16,16)\n",
    "fake_agent_input=torch.randn(32, 32).unsqueeze(2).unsqueeze(3).repeat(1,1,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_encodings=torch.cat([fake_map_encodings,fake_agent_input],dim=1)\n",
    "conv1d1=nn.Conv2d(544, 528, kernel_size=1, stride=1, bias=False)\n",
    "conv1d2=nn.Conv2d(528, 512, kernel_size=1, stride=1, bias=False)\n",
    "test_dim_reduction=nn.Sequential(conv1d1,nn.BatchNorm2d(528),nn.ReLU(),conv1d2,nn.BatchNorm2d(512),nn.ReLU())\n",
    "fake_feature=test_dim_reduction(concatenated_encodings)\n",
    "fake_feature=fake_feature.view(fake_feature.shape[0], fake_feature.shape[1], -1).permute(0, 2, 1)\n",
    "\n",
    "fake_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_test=final_convs(transpose_convs(fake_feature))\n",
    "# augmented_mask=mask.unsqueeze(-1)\n",
    "print(upsampled_test[:,:,::2,::2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# from model.decode import generic_decode\n",
    "\n",
    "# from utils.image import gaussian_radius, draw_umich_gaussian\n",
    "\n",
    "# from model.ConvGRU import ConvGRU\n",
    "\n",
    "from einops import rearrange as rearr, repeat\n",
    "\n",
    "from spatial_correlation_sampler import spatial_correlation_sample\n",
    "\n",
    "\n",
    "class LocalWalk(nn.Module):\n",
    "    def __init__(self, topk=0, radius=0.05, temp=0.05, pad_value=0,\n",
    "            broadcast_val=False, corr_module=True):\n",
    "        super(LocalWalk, self).__init__()\n",
    "\n",
    "        self.topk = topk\n",
    "        self.radius = radius\n",
    "        self.vals = {}\n",
    "        self.idxmaps = {}\n",
    "        self.temp = temp\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "        self.broadcast_val = broadcast_val\n",
    "\n",
    "        self.corr_module = corr_module\n",
    "\n",
    "    def get_identity_label(self, keys):\n",
    "        '''\n",
    "        returns 1 x H*W x H x W as reshaped H*W x H*W identity matrix\n",
    "        '''\n",
    "        B, C, H, W = keys.shape\n",
    "        name = f\"{H}_{W}\"\n",
    "        if name not in self.vals:\n",
    "            vals = self.distance_field(H, W).flatten(0, 1)\n",
    "            vals = (vals == 0).float() ##Returns an identity matrix, which is composed of multiple matrices.\n",
    "            # The i th matrix has an element 1 at the i ith position, the rest places are all zeros.\n",
    "            vals = repeat(vals, 'n h w -> b n h w', b=B if not self.broadcast_val else 1)## Repeat for batch number times\n",
    "            self.vals[name] = vals.to(keys.device)\n",
    "            print('created vals')\n",
    "\n",
    "        return self.vals[name]\n",
    "\n",
    "    def knn(self, A):\n",
    "        if self.pad_value == 0 or self.topk > 0:\n",
    "            with torch.no_grad():\n",
    "                mask = (A == self.pad_value)\n",
    "                if self.topk > 0:\n",
    "                  mask |= (A < A.topk(k=self.topk, dim=-1)[0].min(-1, keepdim=True)[0])\n",
    "            A[mask] = -10\n",
    "\n",
    "        return A\n",
    "\n",
    "    def distance_field(self, H, W, p=2):\n",
    "        gx, gy = torch.meshgrid(torch.arange(0, H), torch.arange(0, W))\n",
    "        D = ( (gx[None, None, :, :] - gx[:, :, None, None]).abs()**p + (gy[None, None, :, :] - gy[:, :, None, None]).abs()**p ).float() #** (1/p)\n",
    "        return D\n",
    "\n",
    "    def make_scatter_map(self, keys, kH, kW):\n",
    "        B, C, H, W = keys.shape\n",
    "        name = f\"{H}_{W}_{kH}_{kW}\"\n",
    "        if name not in self.idxmaps:\n",
    "            idx_map = torch.arange(H*W).view(H, W)[None, None].float()\n",
    "            idx_map = torch.nn.functional.unfold(idx_map, kernel_size=(kH, kW), stride=1, padding=(kH//2, kW//2))\n",
    "            idx_map = rearr(idx_map, 'b n hw -> b hw n')\n",
    "            idx_map = idx_map.clamp(min=0).long()\n",
    "            self.idxmaps[name] = idx_map.to(keys.device)\n",
    "            print('created idx map')\n",
    "\n",
    "        return self.idxmaps[name]\n",
    "\n",
    "    def forward(self, query, keys, val=None):\n",
    "        '''\n",
    "        assumes q, k, v: B D N\n",
    "        '''\n",
    "\n",
    "        B, C, H, W = keys.shape\n",
    "        kW = kH = int(H * self.radius) * 2 + 1\n",
    "\n",
    "        val = self.make_scatter_map(keys, kH, kW)## Returns the indices of elements inside the sliding windows of all steps\n",
    "        ## The sliding window has size (kH,kW), the input is keys.\n",
    "        # out = self.get_identity_label(keys) * 0##Why all zeros?\n",
    "        out = torch.zeros([B,H*W,H,W]).float()\n",
    "        out = repeat(out, '1 n h w -> b (h w) n', b=B) if out.shape[0] == 1 else \\\n",
    "              rearr(out, 'b n h w -> b (h w) n') ##Repeat for batch number\n",
    "\n",
    "        if self.corr_module:\n",
    "            att = spatial_correlation_sample(query,\n",
    "                               keys,\n",
    "                               kernel_size=1,\n",
    "                               patch_size=kH,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               dilation=1,\n",
    "                               dilation_patch=1) / self.temp\n",
    "            att = rearr(att, 'b p1 p2 h w -> b h w (p1 p2)')##Local connectivity, for each node (pixel)\n",
    "            ## calculate its node similarity with nearby nodes\n",
    "\n",
    "        A = self.knn(att)\n",
    "\n",
    "        A = torch.exp(rearr(A, 'b h w n -> b (h w) n'))\n",
    "        out.scatter_add_(2, val.to(A.device).expand_as(A), A)\n",
    "        val = rearr(out, 'b (h w) n -> b n h w', h=H)\n",
    "\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor=torch.randn([32,20,100,100])\n",
    "test_walker=LocalWalk(radius=0.2)\n",
    "test_walker.forward(test_tensor,test_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.library.RasterSampler import *\n",
    "sampler=Sampler(cfg['train_set_args'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mask=torch.randn([32,488,488]).ge(0)\n",
    "nodes_2D=sampler.sample_goals().repeat(32,1,1).type(torch.float32)\n",
    "mask_under=(sampler.sample_mask(mask))\n",
    "attn_mask=~mask_under.unsqueeze(-1).repeat(2,1,256)\n",
    "print(attn_mask.shape)\n",
    "print(mask.shape)\n",
    "print(nodes_2D.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.array(mask[0]))\n",
    "plt.show()\n",
    "plt.imshow(np.array(~mask_under[0].view(122,122)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/stanliu/code/pgp/PGP/configs/preprocess_nuscenes.yml\", 'r') as yaml_file:\n",
    "    cfg = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.nuScenes.nuScenes_graphs import NuScenesGraphs\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=\"/home/stanliu/data/mnt/nuScenes/\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.prediction import PredictHelper\n",
    "helper=PredictHelper(nusc)\n",
    "graph_extractor=NuScenesGraphs('extract_data','/home/stanliu/code/pgp/PGP/preprocess',cfg['train_set_args'],helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extractor.max_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "i_t, s_t = graph_extractor.token_list[idx].split(\"_\")\n",
    "map_name = graph_extractor.helper.get_map_name_from_sample_token(s_t)\n",
    "map_api = graph_extractor.maps[map_name]\n",
    "\n",
    "# Get agent representation in global co-ordinates\n",
    "global_pose = graph_extractor.get_target_agent_global_pose(idx)\n",
    "\n",
    "# Get lanes around agent within map_extent\n",
    "lanes = graph_extractor.get_lanes_around_agent(global_pose, map_api)\n",
    "\n",
    "# Get relevant polygon layers from the map_api\n",
    "polygons = graph_extractor.get_polygons_around_agent(global_pose, map_api)\n",
    "\n",
    "# Get vectorized representation of lanes\n",
    "lane_node_feats, lane_ids = graph_extractor.get_lane_node_feats(global_pose, lanes, polygons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_node_feats, lane_ids = graph_extractor.discard_poses_outside_extent(lane_node_feats, lane_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_succ = graph_extractor.get_successor_edges(lane_ids, map_api)\n",
    "e_prox = graph_extractor.get_proximal_edges(lane_node_feats, e_succ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nbrs = [len(e_succ[i]) + len(e_prox[i]) for i in range(len(e_succ))]\n",
    "max_nbrs = max(num_nbrs) if len(num_nbrs) > 0 else 0\n",
    "num_nodes = len(lane_node_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num_nbrs',(num_nbrs))\n",
    "print('max_nbrs',max_nbrs)\n",
    "print('num_nodes',num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_next, edge_type = graph_extractor.get_edge_lookup(e_succ, e_prox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "lengths=[]\n",
    "segment_lengths=[]\n",
    "for idx in range(len(lane_node_feats)):\n",
    "    lengths.append(LA.norm(lane_node_feats[idx][1:,:2]-lane_node_feats[idx][:-1,:2],axis=1).sum())\n",
    "    segment_lengths.append(LA.norm(lane_node_feats[idx][1:,:2]-lane_node_feats[idx][:-1,:2],axis=1)[0])\n",
    "print(lengths)\n",
    "print(segment_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prev_feat=np.empty([0,5])\n",
    "for feat in lane_node_feats[:2]:\n",
    "    prev_feat=np.r_[prev_feat,feat]\n",
    "idx=-10\n",
    "import matplotlib.pyplot as plt\n",
    "x=prev_feat[:,0]\n",
    "y=prev_feat[:,1]\n",
    "plt.scatter(x,y,s=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pgp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "593542b65644041049b318720dfeebe70f9074a000f082b969de259755a1a643"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
