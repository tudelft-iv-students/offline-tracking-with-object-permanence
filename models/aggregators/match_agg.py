import torch
import torch.nn as nn
from models.aggregators.aggregator import PredictionAggregator
from typing import Dict, Tuple
from models.library.blocks import *


class Match_agg(PredictionAggregator):


    def __init__(self, args: Dict):

        """
        args to include

        enc_size: int Dimension of encodings generated by encoder
        emb_size: int Size of embeddings used for queries, keys and values
        num_heads: int Number of attention heads

        """
        super().__init__()
        self.agg_type=args['agg_method']
        if self.agg_type=='fully_connected':
            self.graph1=GlobalGraph(args['node_enc_size'],args['att_hidden_size'])
            self.graph2=GlobalGraph(args['node_enc_size'],args['att_hidden_size'])
        elif self.agg_type=='GAT':
            self.gat=nn.ModuleList([GAT(args['node_enc_size'], args['node_enc_size'])
                                    for _ in range(args['num_gat_layers'])])
        

    def forward(self, encodings: Dict) -> torch.Tensor:
        """
        Forward pass for attention aggregator
        """
        if self.agg_type=='fully_connected':
            map_enc=encodings['context_encoding']
            lane_node_masks=map_enc['lane_mask']
            lane_node_encodings=map_enc['lane_enc']
            mask_base=(~lane_node_masks[:,:,:,0].bool()).any(-1).unsqueeze(-1)
            attn_mask=(mask_base*mask_base.transpose(1,-1)).float()
            lane_encodings= torch.cat([self.graph1(lane_node_encodings, attn_mask),
                                        self.graph2(lane_node_encodings, attn_mask)], dim=-1)
            encodings['context_encoding']['lane_enc']=lane_encodings
        elif self.agg_type=='GAT':
            map_enc=encodings['context_encoding']
            lane_node_enc=map_enc['lane_enc']
            adj_mat = self.build_adj_mat(map_enc['s_next'], map_enc['edge_type'])
            for gat_layer in self.gat:
                lane_node_enc += gat_layer(lane_node_enc, adj_mat)
            encodings['context_encoding']['lane_enc']=lane_node_enc
        return encodings

    @staticmethod
    def get_combined_encodings(context_enc: Dict) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Creates a combined set of map and surrounding agent encodings to be aggregated using attention.
        """
        encodings = []
        masks = []
        if 'map' in context_enc:
            encodings.append(context_enc['map'])
            masks.append(context_enc['map_masks'])
        if 'vehicles' in context_enc:
            encodings.append(context_enc['vehicles'])
            masks.append(context_enc['vehicle_masks'])
        if 'pedestrians' in context_enc:
            encodings.append(context_enc['pedestrians'])
            masks.append(context_enc['pedestrian_masks'])
        combined_enc = torch.cat(encodings, dim=1)
        combined_masks = torch.cat(masks, dim=1).bool()
        return combined_enc, combined_masks
    
    @staticmethod
    def build_adj_mat(s_next, edge_type):
        """
        Builds adjacency matrix for GAT layers.
        """
        batch_size = s_next.shape[0]
        max_nodes = s_next.shape[1]
        max_edges = s_next.shape[2]
        adj_mat = torch.diag(torch.ones(max_nodes, device=s_next.device)).unsqueeze(0).repeat(batch_size, 1, 1).bool()

        dummy_vals = torch.arange(max_nodes, device=s_next.device).unsqueeze(0).unsqueeze(2).repeat(batch_size, 1, max_edges)
        dummy_vals = dummy_vals.float()
        s_next[edge_type == 0] = dummy_vals[edge_type == 0]
        batch_indices = torch.arange(batch_size).unsqueeze(1).unsqueeze(2).repeat(1, max_nodes, max_edges)
        src_indices = torch.arange(max_nodes).unsqueeze(0).unsqueeze(2).repeat(batch_size, 1, max_edges)
        adj_mat[batch_indices[:, :, :-1], src_indices[:, :, :-1], s_next[:, :, :-1].long()] = True
        adj_mat = adj_mat | torch.transpose(adj_mat, 1, 2)

        return adj_mat
    
    


